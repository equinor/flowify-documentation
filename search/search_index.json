{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Flowify Flowify is a no-code portal for creating and running workflows on Argo Workflows. Developers can create sharable components for no-code users No-user uses a drag-and-connect user-interface to build workflows from components Workspaces implementation allows granular access control Build on top of Argo Workflow to provide a robust workflow executor Flowify is not just a Argo Workflows builder. Easy to share re-usable components Version control for workflows and components Designed to make data flow more explicit while Argo Workflows handles execution flow No Argo Workflows knowledge is needed for the end user Transpilation layer provides flexibility and allows future implementation of other executor Flowify consists of two components that work in tandem A backend server written in Golang for: Two-way communication with Argo Workflows Transpile frontend manifest into Argo Workflow manifest Handle secrets and volume mount through Kubernetes Implement access control A React based UI for: Creating Flowify frontend manifest from GUI Allowing users to use Argo Workflows without knowing Argo Workflows","title":"Home"},{"location":"#welcome-to-flowify","text":"Flowify is a no-code portal for creating and running workflows on Argo Workflows. Developers can create sharable components for no-code users No-user uses a drag-and-connect user-interface to build workflows from components Workspaces implementation allows granular access control Build on top of Argo Workflow to provide a robust workflow executor Flowify is not just a Argo Workflows builder. Easy to share re-usable components Version control for workflows and components Designed to make data flow more explicit while Argo Workflows handles execution flow No Argo Workflows knowledge is needed for the end user Transpilation layer provides flexibility and allows future implementation of other executor","title":"Welcome to Flowify"},{"location":"#flowify-consists-of-two-components-that-work-in-tandem","text":"A backend server written in Golang for: Two-way communication with Argo Workflows Transpile frontend manifest into Argo Workflow manifest Handle secrets and volume mount through Kubernetes Implement access control A React based UI for: Creating Flowify frontend manifest from GUI Allowing users to use Argo Workflows without knowing Argo Workflows","title":"Flowify consists of two components that work in tandem"},{"location":"about/","text":"Flowify is developed and maintained by Equinor ASA Licensed under Apache License Version 2.0","title":"About"},{"location":"arch/","text":"Deployment architecture C4Context title Flowify deployment Person(customerA, \"User\") Deployment_Node(b0, \"Kubernetes\") { Node(b1, \"Flowify namespace\") { Container(SystemH, \"OAuth2 proxy\", \"Authorization to UI\") Container(SystemE, \"Nginx - Flowify Frontend\", \"Serves Flowify UI\") Container(SystemC, \"Flowify server\", \"Flowify API and transpiler\") ContainerDb(mongo, \"MongoDB\") Container(SystemC, \"Flowify server\", \"Flowify API and transpiler\") ContainerDb(artifact, \"Artifacts storage\") Container(SystemI, \"Argo Workflows\", \"Flowify API and transpiler\") } Node(b2, \"Workspace namespace\") { Container(task, \"Workflow tasks\") Component(SystemA, \"Secrets\") Component(SystemB, \"Volume mount\") } } Rel(task, SystemA, \"Uses\") Rel(task, SystemB, \"Uses\") BiRel(SystemI, task, \"Uses\") BiRel(SystemI, artifact, \"Uses\") BiRel(SystemC, mongo, \"Uses\") BiRel(SystemC, SystemI, \"Uses\") BiRel(customerA, SystemH, \"Uses\") BiRel(SystemC, SystemE, \"RESTapi\") BiRel(SystemH, SystemE, \"HTTPS\") UpdateRelStyle(customerA, SystemAA, $textColor=\"blue\", $lineColor=\"blue\", $offsetX=\"5\") UpdateRelStyle(SystemAA, SystemE, $textColor=\"blue\", $lineColor=\"blue\", $offsetY=\"-10\") UpdateRelStyle(SystemAA, SystemC, $textColor=\"blue\", $lineColor=\"blue\", $offsetY=\"-40\", $offsetX=\"-50\") UpdateRelStyle(SystemC, customerA, $textColor=\"red\", $lineColor=\"red\", $offsetX=\"-50\", $offsetY=\"20\")","title":"Architecture"},{"location":"arch/#deployment-architecture","text":"C4Context title Flowify deployment Person(customerA, \"User\") Deployment_Node(b0, \"Kubernetes\") { Node(b1, \"Flowify namespace\") { Container(SystemH, \"OAuth2 proxy\", \"Authorization to UI\") Container(SystemE, \"Nginx - Flowify Frontend\", \"Serves Flowify UI\") Container(SystemC, \"Flowify server\", \"Flowify API and transpiler\") ContainerDb(mongo, \"MongoDB\") Container(SystemC, \"Flowify server\", \"Flowify API and transpiler\") ContainerDb(artifact, \"Artifacts storage\") Container(SystemI, \"Argo Workflows\", \"Flowify API and transpiler\") } Node(b2, \"Workspace namespace\") { Container(task, \"Workflow tasks\") Component(SystemA, \"Secrets\") Component(SystemB, \"Volume mount\") } } Rel(task, SystemA, \"Uses\") Rel(task, SystemB, \"Uses\") BiRel(SystemI, task, \"Uses\") BiRel(SystemI, artifact, \"Uses\") BiRel(SystemC, mongo, \"Uses\") BiRel(SystemC, SystemI, \"Uses\") BiRel(customerA, SystemH, \"Uses\") BiRel(SystemC, SystemE, \"RESTapi\") BiRel(SystemH, SystemE, \"HTTPS\") UpdateRelStyle(customerA, SystemAA, $textColor=\"blue\", $lineColor=\"blue\", $offsetX=\"5\") UpdateRelStyle(SystemAA, SystemE, $textColor=\"blue\", $lineColor=\"blue\", $offsetY=\"-10\") UpdateRelStyle(SystemAA, SystemC, $textColor=\"blue\", $lineColor=\"blue\", $offsetY=\"-40\", $offsetX=\"-50\") UpdateRelStyle(SystemC, customerA, $textColor=\"red\", $lineColor=\"red\", $offsetX=\"-50\", $offsetY=\"20\")","title":"Deployment architecture"},{"location":"auth/","text":"Access to the frontend is controlled by a sidecar running OAuth2 Proxy . You can use any other OIDC client as long as: JWT ID Token is set in Authorization header JWT token contains role claims ID Token issued by the following providers are supported by the backend server: Azure See Developer Guide for adding OIDC provider support.","title":"Authentication and Authorization"},{"location":"bricks/","text":"Concept The brick component is an representation of Argo Workflow's Container template . The implementation at run time is handled by Argo Workflow. Flowify is responsible for generating the Container template when used in a workflow. The core of a brick component consists of a OCI compliant container image. It is then wrapped around by a layer of input/output parameters, secrets and volumes. They are applied to the container by Argo Workflow as follows: Input parameters: Appened to the Entrypoint of the container Output parameters: Copied and its values extracted from the container on completion Input/Output Artifacts: Handled by Argo Workflow and copied to and from the container Secrets: As environmental variables Volumne mount: Mount to the container using a corresponding CSI driver One difference on the user level to Argo Workflow is Flowify handle Artifacts as Input/Output instead of a separate entity. It makes allows a more explicit and declarative data flow. Private container registry Pulling of container images from private registry is handled either by Argo Workflows or Kubernetes . Flowify does not verify if the cluster has permission to pull the image. Building a brick Prerequisities: Basic knowledge of container A published OCI compliant container image Basic setup In this example we will build a brick component that perform a HTTP GET request and uses the response as output Example image: ghcr.io/equinor/flowify-component-http:0.0.1 As Flowify uses Argo Workflows as executor, ENTRYPOINT must be defined explicitly in command: Args are appended to the ENTRYPOINT command. They can be a constant (e.g. http_method=get ) or variables from input parameters (e.g. url= ). In this example, the full command will be node ./src/index.js http_method=get url=<INPUT_URL_FROM_FLOWIFY_PARAMETER> Setting constant parameter. (Fixed for all execution) Input parameter. (Variables injected by workflow) Setting output parameter Add an output on the left-hand pane and choose the correct Type . Use Parameter_array if you would like to utilize the parallelized Map component feature, otherwise use Parameter . When using Parameter_array , Flowify will try to parse the output as array. The content of the output file is expected to be [1, 2, 3] . More details . Mediatype is only for annotation purpose. The container saves the GET response under /tmp/files/output.json . We will need to define an output on the left-hand pane and mapped it to results on the right-hand pane. Flowify/Argo Workflows will extract values from the file and passes to the next component as input. Overview Using files (Artifacts) Instead of parameter values, it is possible to pass data across components using a file (Artifact). It is advised to limit the usage of Artifacts in order to keep data flow lineage explicit. An Artifact Repository must be configured in Argo Workflows. Flowify does not verify the configurations. File as input Add an component input on the left-hand pane and select artifacts as input type. Pass the path location of the artifact inside the container as Args . In this example, the full path will be available as `file=/artifacts/input_file in the container run arguments. The path of the input artifact is /artifacts/<INPUT_PARAMETER_NAME> . You will need to make sure the container has the permission to access the file. See volume mount example File as output Select artifacts as output type on the left-hand pane. The file will be used as parameter in a workflow. Contents of the file will not be extracted. Add secrets To add secrets to the component, add them on the left-hand pane. The secrets will be available as Environmental variables inside the container with the same name. Naming must not begin with digits and not contain spaces (use dash _ ). It is conventional to use all uppercase characters. In this example the name of the environmental variable is LOGIN_CREDENTIAL . The value will be injected by a workflow. Add volume mount Add volume mount as brick input on the left-hand pane. Afterwards, add an Args on the right-hand pane. If leaving out prefix and suffix, the mount path to the container will be /<NAME_OF_VOLUME_INPUT> . The volume mount argument will not be appended to the `docker run arguments . As the container is run as non-root in Flowify, make sure the container has read permission to the mount path. It can be achieved in Dockerfile for example: RUN mkdir /<NAME_OF_VOLUME_INPUT> RUN chmod -R 777 /<NAME_OF_VOLUME_INPUT> It is advised to limit the usage of volume mount in order to keep data flow lineage explicit. Versioning and modifications Under development","title":"Bricks"},{"location":"bricks/#concept","text":"The brick component is an representation of Argo Workflow's Container template . The implementation at run time is handled by Argo Workflow. Flowify is responsible for generating the Container template when used in a workflow. The core of a brick component consists of a OCI compliant container image. It is then wrapped around by a layer of input/output parameters, secrets and volumes. They are applied to the container by Argo Workflow as follows: Input parameters: Appened to the Entrypoint of the container Output parameters: Copied and its values extracted from the container on completion Input/Output Artifacts: Handled by Argo Workflow and copied to and from the container Secrets: As environmental variables Volumne mount: Mount to the container using a corresponding CSI driver One difference on the user level to Argo Workflow is Flowify handle Artifacts as Input/Output instead of a separate entity. It makes allows a more explicit and declarative data flow.","title":"Concept"},{"location":"bricks/#private-container-registry","text":"Pulling of container images from private registry is handled either by Argo Workflows or Kubernetes . Flowify does not verify if the cluster has permission to pull the image.","title":"Private container registry"},{"location":"bricks/#building-a-brick","text":"Prerequisities: Basic knowledge of container A published OCI compliant container image","title":"Building a brick"},{"location":"bricks/#basic-setup","text":"In this example we will build a brick component that perform a HTTP GET request and uses the response as output Example image: ghcr.io/equinor/flowify-component-http:0.0.1 As Flowify uses Argo Workflows as executor, ENTRYPOINT must be defined explicitly in command: Args are appended to the ENTRYPOINT command. They can be a constant (e.g. http_method=get ) or variables from input parameters (e.g. url= ). In this example, the full command will be node ./src/index.js http_method=get url=<INPUT_URL_FROM_FLOWIFY_PARAMETER>","title":"Basic setup"},{"location":"bricks/#setting-constant-parameter-fixed-for-all-execution","text":"","title":"Setting constant parameter. (Fixed for all execution)"},{"location":"bricks/#input-parameter-variables-injected-by-workflow","text":"","title":"Input parameter. (Variables injected by workflow)"},{"location":"bricks/#setting-output-parameter","text":"Add an output on the left-hand pane and choose the correct Type . Use Parameter_array if you would like to utilize the parallelized Map component feature, otherwise use Parameter . When using Parameter_array , Flowify will try to parse the output as array. The content of the output file is expected to be [1, 2, 3] . More details . Mediatype is only for annotation purpose. The container saves the GET response under /tmp/files/output.json . We will need to define an output on the left-hand pane and mapped it to results on the right-hand pane. Flowify/Argo Workflows will extract values from the file and passes to the next component as input.","title":"Setting output parameter"},{"location":"bricks/#overview","text":"","title":"Overview"},{"location":"bricks/#using-files-artifacts","text":"Instead of parameter values, it is possible to pass data across components using a file (Artifact). It is advised to limit the usage of Artifacts in order to keep data flow lineage explicit. An Artifact Repository must be configured in Argo Workflows. Flowify does not verify the configurations.","title":"Using files (Artifacts)"},{"location":"bricks/#file-as-input","text":"Add an component input on the left-hand pane and select artifacts as input type. Pass the path location of the artifact inside the container as Args . In this example, the full path will be available as `file=/artifacts/input_file in the container run arguments. The path of the input artifact is /artifacts/<INPUT_PARAMETER_NAME> . You will need to make sure the container has the permission to access the file. See volume mount example","title":"File as input"},{"location":"bricks/#file-as-output","text":"Select artifacts as output type on the left-hand pane. The file will be used as parameter in a workflow. Contents of the file will not be extracted.","title":"File as output"},{"location":"bricks/#add-secrets","text":"To add secrets to the component, add them on the left-hand pane. The secrets will be available as Environmental variables inside the container with the same name. Naming must not begin with digits and not contain spaces (use dash _ ). It is conventional to use all uppercase characters. In this example the name of the environmental variable is LOGIN_CREDENTIAL . The value will be injected by a workflow.","title":"Add secrets"},{"location":"bricks/#add-volume-mount","text":"Add volume mount as brick input on the left-hand pane. Afterwards, add an Args on the right-hand pane. If leaving out prefix and suffix, the mount path to the container will be /<NAME_OF_VOLUME_INPUT> . The volume mount argument will not be appended to the `docker run arguments . As the container is run as non-root in Flowify, make sure the container has read permission to the mount path. It can be achieved in Dockerfile for example: RUN mkdir /<NAME_OF_VOLUME_INPUT> RUN chmod -R 777 /<NAME_OF_VOLUME_INPUT> It is advised to limit the usage of volume mount in order to keep data flow lineage explicit.","title":"Add volume mount"},{"location":"bricks/#versioning-and-modifications","text":"Under development","title":"Versioning and modifications"},{"location":"community/","text":"Need help? Feature requests? Or just want to say hi? https://github.com/equinor/flowify-workflows-server/discussions","title":"Community"},{"location":"components/","text":"Component is the basic building block of a workflow. It can be a single container (brick) or a series of container (Graph) A brick component is the most basic form of component. It consist of a single OCI compliant container and input/output parameters. A graph component allow you to encapsulate a workflow like object into a component and improve user experience. A special type of component: Any is available as a placeholder. It allows you to mock a component and workflow with inputs and outputs for conceptualization and subsequent implementation. Example components Example container images for components are located here . Access control Components are available across all workspaces. Implementation of workspace scoped components is under development. Create All user can create components Modify All user can modify component and publish new version. It is not permitted to modify published version to avoid breaking any existing workflows. Delete Workspace admin can delete component. WARNING: It may cause breaking change to any existing workflow that use it. It should be used with cautions.","title":"Concept"},{"location":"components/#example-components","text":"Example container images for components are located here .","title":"Example components"},{"location":"components/#access-control","text":"Components are available across all workspaces. Implementation of workspace scoped components is under development.","title":"Access control"},{"location":"components/#create","text":"All user can create components","title":"Create"},{"location":"components/#modify","text":"All user can modify component and publish new version. It is not permitted to modify published version to avoid breaking any existing workflows.","title":"Modify"},{"location":"components/#delete","text":"Workspace admin can delete component. WARNING: It may cause breaking change to any existing workflow that use it. It should be used with cautions.","title":"Delete"},{"location":"concepts/","text":"The basic building block of Flowify is a component. Components are built by users with some programming background. No-code users are then able to construct workflows from components using a drag and connect interface. Workspaces define the working environment for no-code users and provide security sandbox through features provided by Kubernetes and Argo Workflows. Workflows, Secrets and volume mount are scoped to their respective workspace. Each workspace has their own Kubernetes namespace for execution of workflows, volume mount and secrets.","title":"Concepts"},{"location":"dev_env/","text":"We welcome all kinds of contributions, including code, bug reports, issues, feature requests, and documentation. The preferred way of submitting a contribution is to either make an issue on github or by forking the project on github and making a pull request. The frontend is hosted at https://github.com/equinor/flowify-workflows-ui The backend is hosted at https://github.com/equinor/flowify-workflows-server Documentation is hosted at https://github.com/equinor/flowify-documentation Please visit the repos for instructions on setting up development environment. Backlogs https://github.com/orgs/equinor/projects/269/views/1","title":"Contributing"},{"location":"dev_env/#backlogs","text":"https://github.com/orgs/equinor/projects/269/views/1","title":"Backlogs"},{"location":"getting_started/","text":"Getting Started We provide a docker-compose file for testing out Flowify on your local host machine . For production install, please check out the Deployment section.","title":"Prerequisites"},{"location":"getting_started/#getting-started","text":"We provide a docker-compose file for testing out Flowify on your local host machine . For production install, please check out the Deployment section.","title":"Getting Started"},{"location":"graphs/","text":"Concept Flowify allows developer to present a workflow object to the end-user as a component. It adds a level of encapsulation and improvement to user experience. A graph component itself is a DAG in Argo Workflows. When used in a workflow, the graph component is representated by a nested DAG in Argo Workflows. Building a graph Building a graph is similar to building a workflow. Please see Workflows for details.","title":"Graph"},{"location":"graphs/#concept","text":"Flowify allows developer to present a workflow object to the end-user as a component. It adds a level of encapsulation and improvement to user experience. A graph component itself is a DAG in Argo Workflows. When used in a workflow, the graph component is representated by a nested DAG in Argo Workflows.","title":"Concept"},{"location":"graphs/#building-a-graph","text":"Building a graph is similar to building a workflow. Please see Workflows for details.","title":"Building a graph"},{"location":"if/","text":"This feature is experimental. Concept flowchart LR A[Random number generator] --> |2|B{Run A if output > 1, else B} B -->|2| C[A] flowchart LR A[Random number generator] --> |0|B{Run A if output > 1, else B} B -->|0| C[B]","title":"If/else"},{"location":"if/#concept","text":"flowchart LR A[Random number generator] --> |2|B{Run A if output > 1, else B} B -->|2| C[A] flowchart LR A[Random number generator] --> |0|B{Run A if output > 1, else B} B -->|0| C[B]","title":"Concept"},{"location":"issues/","text":"List of known issues is available at https://github.com/equinor/flowify-workflows-server/labels/known_issue","title":"Known issues"},{"location":"jobs/","text":"Concept When a workflow is submmited, the backend transpiler will construct a Argo Workflows manifest and submit it using Argo Workflows interface. Run a workflow You can run a workflow by on the workflow edit page or on the workspace dashboardpage. Before the job is sent, you can edit and review the input parameters. The new parameters are not saved. To change defaults input parameters, edit them on the left-hand pane in workflow editor and save as new version Following a job Job status is continuously updated on the UI. There is also possibility to stop or delete a job. Stopping a running job will terminate execution on Argo Workflows and the job will be marked as terminated. Deleteing a job will remove it from the Argo Workflows and stop it if it is currently running","title":"Jobs"},{"location":"jobs/#concept","text":"When a workflow is submmited, the backend transpiler will construct a Argo Workflows manifest and submit it using Argo Workflows interface.","title":"Concept"},{"location":"jobs/#run-a-workflow","text":"You can run a workflow by on the workflow edit page or on the workspace dashboardpage. Before the job is sent, you can edit and review the input parameters. The new parameters are not saved. To change defaults input parameters, edit them on the left-hand pane in workflow editor and save as new version","title":"Run a workflow"},{"location":"jobs/#following-a-job","text":"Job status is continuously updated on the UI. There is also possibility to stop or delete a job. Stopping a running job will terminate execution on Argo Workflows and the job will be marked as terminated. Deleteing a job will remove it from the Argo Workflows and stop it if it is currently running","title":"Following a job"},{"location":"map/","text":"This feature is experimental. Concept Flowify has a built-in Map component to allow parallel running of components. A map component wrap around a brick/graph component with the same inputs and outputs. The map component needs to have one input as parameter array. A workflow will spawn a new component for each item in the parameter array. At the end of the run, outputs will be aggregated into an parameter array. This feature is currently only available when output are parameters instead of artifacts. flowchart LR A[Input array 1, 2] -- 1 ---B[Multiply by 2] A[Input array 1, 2] -- 2 ---C[Multiply by 2] B --> |2| D[Output array 2,4] C --> |4| D","title":"Parallel tasks"},{"location":"map/#concept","text":"Flowify has a built-in Map component to allow parallel running of components. A map component wrap around a brick/graph component with the same inputs and outputs. The map component needs to have one input as parameter array. A workflow will spawn a new component for each item in the parameter array. At the end of the run, outputs will be aggregated into an parameter array. This feature is currently only available when output are parameters instead of artifacts. flowchart LR A[Input array 1, 2] -- 1 ---B[Multiply by 2] A[Input array 1, 2] -- 2 ---C[Multiply by 2] B --> |2| D[Output array 2,4] C --> |4| D","title":"Concept"},{"location":"mounts/","text":"Concept Volume mount allows mounting a of cloud storage volume on the container without explicitly carrying out download/upload operations inside the container. It can be used to load large data set from Blob Storage and take advantage of built-in caching/buffering capabilities of a CSI driver. An example of CSI driver is Azure Blob Storage CSI . However, it is advised to limit the usage of volume mount in order to keep data flow lineage explicit to the end user. Mounting of a volume is handled by Kubernetes. Flowify and Argo Workflows does not verify if the correct CSI driver is installed on the Kubernetes cluster. The Flowify volume mount configuration is transpiled into CSIVolumeSource in Argo Workflows manifest. Access Control Workspace admin can create, modify and delete Volume mount. The reference to the volume mount is available to all workspace user for use in workflows. Add volume mount to workspace Go to workspace admin page. The volume name will be the name that is presented to the user to select on building workflows. The actual name of the volume as environmental variables is dictated by a component . Setup (Shown example for Azure Blob CSI) Parameter name Description Volume name Name presented to users for building workflow Drive Kubernetes CSI driver Container name Name of Azure Blob Container (For blob csi) Mount options Options relavent to the CSI driver Secret name Name of Kubernetes secret for authentication Add credentials for the CSI driver A kubernetes secret has to be manually set on the cluster in the same namespace as the workspace See https://github.com/kubernetes-sigs/blob-csi-driver/blob/master/deploy/example/e2e_usage.md#option2-use-secret Example: Setting credentials for Azure Blob Storage The Kubernetes secret has to contain the following two keys: azurestorageaccountname azurestorageaccountkey Details Alternative setup It is possible to supply CSIVolumeSource as JSON format. Flowify will append it to the Argo Workflows manifest. See Components and Workflow for usage","title":"Volume mount"},{"location":"mounts/#concept","text":"Volume mount allows mounting a of cloud storage volume on the container without explicitly carrying out download/upload operations inside the container. It can be used to load large data set from Blob Storage and take advantage of built-in caching/buffering capabilities of a CSI driver. An example of CSI driver is Azure Blob Storage CSI . However, it is advised to limit the usage of volume mount in order to keep data flow lineage explicit to the end user. Mounting of a volume is handled by Kubernetes. Flowify and Argo Workflows does not verify if the correct CSI driver is installed on the Kubernetes cluster. The Flowify volume mount configuration is transpiled into CSIVolumeSource in Argo Workflows manifest.","title":"Concept"},{"location":"mounts/#access-control","text":"Workspace admin can create, modify and delete Volume mount. The reference to the volume mount is available to all workspace user for use in workflows.","title":"Access Control"},{"location":"mounts/#add-volume-mount-to-workspace","text":"Go to workspace admin page. The volume name will be the name that is presented to the user to select on building workflows. The actual name of the volume as environmental variables is dictated by a component .","title":"Add volume mount to workspace"},{"location":"mounts/#setup-shown-example-for-azure-blob-csi","text":"Parameter name Description Volume name Name presented to users for building workflow Drive Kubernetes CSI driver Container name Name of Azure Blob Container (For blob csi) Mount options Options relavent to the CSI driver Secret name Name of Kubernetes secret for authentication","title":"Setup (Shown example for Azure Blob CSI)"},{"location":"mounts/#add-credentials-for-the-csi-driver","text":"A kubernetes secret has to be manually set on the cluster in the same namespace as the workspace See https://github.com/kubernetes-sigs/blob-csi-driver/blob/master/deploy/example/e2e_usage.md#option2-use-secret","title":"Add credentials for the CSI driver"},{"location":"mounts/#example-setting-credentials-for-azure-blob-storage","text":"The Kubernetes secret has to contain the following two keys: azurestorageaccountname azurestorageaccountkey Details","title":"Example: Setting credentials for Azure Blob Storage"},{"location":"mounts/#alternative-setup","text":"It is possible to supply CSIVolumeSource as JSON format. Flowify will append it to the Argo Workflows manifest. See Components and Workflow for usage","title":"Alternative setup"},{"location":"oidc/","text":"Concept Flowify uses a token based authentication system based on the AuthClient - and User -interfaces in \"github.com/equinor/flowify-workflows/auth\" and \"github.com/equinor/flowify-workflows/user\". This is a plugin architecture where each project can implement its own way of authenticating and authorizing users and requests. The authenticatation layer is placed as a middleware that processes incoming requests. An auth implementation typically grants access and authorizes users based on 'Authentication' and 'Authorization' headers, but this is not mandated. Details The User interface // tightly modelled on JWT: http://jwt.io type User interface { // a unique id connected with each user, eg Azure's oid token claim GetUid () string // the full name of a user, not used for identification only searching and ordering GetName () string // the user's email address GetEmail () string // the roles that a user has been granted, to be used in access control GetRoles () [] Role } The AuthClient interface type AuthClient interface { // The authentication layer is performed as a middleware before any resources // can be accessed // * If the authentication returns a non-nil error the middleware // stops the processing and returns an error resonse // * If the error is nil the user object is required to be valid Authenticate ( r * http . Request ) ( user . User , error ) } Implementing the AuthClient interface The auth package contains a mock implementation that reads a static user on server startup, and always passes authentication with the credentials of the given user. // the mock authenticator can be used for testing type MockAuthenticator struct { User user . MockUser } func ( m MockAuthenticator ) Authenticate ( r * http . Request ) ( user . User , error ) { return m . User , nil } Retrieving user information for a granted request When a request is granted access further processing is done with an augmented Contex containing the given user implementaion. This User interface object can be queried for Roles used to authorize access to resources that require access control (RBAC). The user package contains the following utility to simplify access // retrieve a User object from the context if available, otherwise return nil func GetUser ( ctx context . Context ) User All Handler s in the api are required to have this context.","title":"Add OIDC provider"},{"location":"oidc/#concept","text":"Flowify uses a token based authentication system based on the AuthClient - and User -interfaces in \"github.com/equinor/flowify-workflows/auth\" and \"github.com/equinor/flowify-workflows/user\". This is a plugin architecture where each project can implement its own way of authenticating and authorizing users and requests. The authenticatation layer is placed as a middleware that processes incoming requests. An auth implementation typically grants access and authorizes users based on 'Authentication' and 'Authorization' headers, but this is not mandated.","title":"Concept"},{"location":"oidc/#details","text":"The User interface // tightly modelled on JWT: http://jwt.io type User interface { // a unique id connected with each user, eg Azure's oid token claim GetUid () string // the full name of a user, not used for identification only searching and ordering GetName () string // the user's email address GetEmail () string // the roles that a user has been granted, to be used in access control GetRoles () [] Role } The AuthClient interface type AuthClient interface { // The authentication layer is performed as a middleware before any resources // can be accessed // * If the authentication returns a non-nil error the middleware // stops the processing and returns an error resonse // * If the error is nil the user object is required to be valid Authenticate ( r * http . Request ) ( user . User , error ) }","title":"Details"},{"location":"oidc/#implementing-the-authclient-interface","text":"The auth package contains a mock implementation that reads a static user on server startup, and always passes authentication with the credentials of the given user. // the mock authenticator can be used for testing type MockAuthenticator struct { User user . MockUser } func ( m MockAuthenticator ) Authenticate ( r * http . Request ) ( user . User , error ) { return m . User , nil }","title":"Implementing the AuthClient interface"},{"location":"oidc/#retrieving-user-information-for-a-granted-request","text":"When a request is granted access further processing is done with an augmented Contex containing the given user implementaion. This User interface object can be queried for Roles used to authorize access to resources that require access control (RBAC). The user package contains the following utility to simplify access // retrieve a User object from the context if available, otherwise return nil func GetUser ( ctx context . Context ) User All Handler s in the api are required to have this context.","title":"Retrieving user information for a granted request"},{"location":"roles/","text":"","title":"Setting up roles"},{"location":"run_k8s/","text":"","title":"Deployment"},{"location":"run_local/","text":"To run Flowify locally: Requirements: Docker Docker compose curl -Os https://raw.githubusercontent.com/equinor/flowify-documentation/main/docs/assets/docker-compose.yaml docker compose up -d It will take 1-2 minutes for the local cluster to start. After that, the frontend will be available at http://localhost:8080 Flowify will start with an emtpy database. To load the example database: docker exec mongo_server mongorestore dump The setup has been tested on: Ubuntu 22.04, Ubuntu 20.04, WSL 2 Docker 20.10, Docker Compose v2.10 Known issues: Workspace creation is not available for local run. You can only work with the built-in sandbox workspace. Does not work on Chrome OS crostini due to unsupported kind cluster Additional setup required when using Docker Desktop . Launching from Docker CLI is not affected. Does not work in Github Codespace. We are investigating.","title":"Local install"},{"location":"secrets/","text":"Concept Secrets allow passing sensitive information to the workflows such as login credentials to a resource. Secrets are workspace scoped and stored as Kubernetes secrets in workspace's own Kubernetes namespace. The reference to the secrets is transpiled by Flowify into Argo Workflow manifest . They are available as environment variables in the container. Access Control Workspace admin can create, modify and delete secrets. The reference to the secrets is available to all workspace user for use in workflows. Once a secret is added or modified, the secret value is not available to view on the frontend. Add secret to workspace Go to workspace admin page. The secret name will be the name that is presented to the user to select on building workflows. The actually name of the secret as environmental variables is dictated by a component . See Components and Workflow for usage","title":"Secrets"},{"location":"secrets/#concept","text":"Secrets allow passing sensitive information to the workflows such as login credentials to a resource. Secrets are workspace scoped and stored as Kubernetes secrets in workspace's own Kubernetes namespace. The reference to the secrets is transpiled by Flowify into Argo Workflow manifest . They are available as environment variables in the container.","title":"Concept"},{"location":"secrets/#access-control","text":"Workspace admin can create, modify and delete secrets. The reference to the secrets is available to all workspace user for use in workflows. Once a secret is added or modified, the secret value is not available to view on the frontend.","title":"Access Control"},{"location":"secrets/#add-secret-to-workspace","text":"Go to workspace admin page. The secret name will be the name that is presented to the user to select on building workflows. The actually name of the secret as environmental variables is dictated by a component . See Components and Workflow for usage","title":"Add secret to workspace"},{"location":"workflows/","text":"Concept Workflow is Flowify's representation of Argo Workflow's DAG . For the end user, it is a series of component with their outputs connected to others input. When a run is triggered, Flowify will transpile the manifest into Argo Workflow's manifest and submit the job. The progress and results are tracked in Jobs Access Control All workflows are restricted to the workspace that it was created under. Create All workspace user can create workflows Modify All workspace user can modify workflow and publish new version. It is not permitted to modify published version. Running the workflow All workspace user can run workflows in a workspace with/without modifying parameters. Delete Workspace admin can delete any workflow. Building a workflow We will use the HTTP GET component from building a brick to fetch an array(list) of random number from https://www.randomnumberapi.com/api/v1.0/random?count=10 . As the API returns an array of number, try to build a new brick component that extract the an item of an array and set the item as an output. Objective We set an workflow input (a URL) and pass it into the HTTP GET component. The HTTP GET component will output an array of numbers. The array will then passed into another component extracting the first item and print to log. Adding components Add required components from marketplace Adding workflow inputs Add URL as workflow input parameter. Use https://www.randomnumberapi.com/api/v1.0/random?count=10 as value. The value can be modified before running the workflow. Add the index (position) of the number that you need to extract from the array Linking the components Connect the dots on the components by drag and connect. Hover your cursor on the dot shows type hint of the parameter. Connect the workflow URL input parameter to the HTTP GET component URL input parameter. Connect the index paramter to the get element by index component. Connect the output node from HTTP GET component to the get element by index component. Overview Setting Secrets If a component requires secret, it will be shown on the component box. Click on the red text to add secret from the workspace. Workspace secret has to be setup by admin. Volume mount Volume mount can be added in a similar way as secret. Workspace volume has to be setup by admin. Running a workflow See Jobs","title":"Concept"},{"location":"workflows/#concept","text":"Workflow is Flowify's representation of Argo Workflow's DAG . For the end user, it is a series of component with their outputs connected to others input. When a run is triggered, Flowify will transpile the manifest into Argo Workflow's manifest and submit the job. The progress and results are tracked in Jobs","title":"Concept"},{"location":"workflows/#access-control","text":"All workflows are restricted to the workspace that it was created under.","title":"Access Control"},{"location":"workflows/#create","text":"All workspace user can create workflows","title":"Create"},{"location":"workflows/#modify","text":"All workspace user can modify workflow and publish new version. It is not permitted to modify published version.","title":"Modify"},{"location":"workflows/#running-the-workflow","text":"All workspace user can run workflows in a workspace with/without modifying parameters.","title":"Running the workflow"},{"location":"workflows/#delete","text":"Workspace admin can delete any workflow.","title":"Delete"},{"location":"workflows/#building-a-workflow","text":"We will use the HTTP GET component from building a brick to fetch an array(list) of random number from https://www.randomnumberapi.com/api/v1.0/random?count=10 . As the API returns an array of number, try to build a new brick component that extract the an item of an array and set the item as an output.","title":"Building a workflow"},{"location":"workflows/#objective","text":"We set an workflow input (a URL) and pass it into the HTTP GET component. The HTTP GET component will output an array of numbers. The array will then passed into another component extracting the first item and print to log.","title":"Objective"},{"location":"workflows/#adding-components","text":"Add required components from marketplace","title":"Adding components"},{"location":"workflows/#adding-workflow-inputs","text":"Add URL as workflow input parameter. Use https://www.randomnumberapi.com/api/v1.0/random?count=10 as value. The value can be modified before running the workflow. Add the index (position) of the number that you need to extract from the array","title":"Adding workflow inputs"},{"location":"workflows/#linking-the-components","text":"Connect the dots on the components by drag and connect. Hover your cursor on the dot shows type hint of the parameter. Connect the workflow URL input parameter to the HTTP GET component URL input parameter. Connect the index paramter to the get element by index component. Connect the output node from HTTP GET component to the get element by index component. Overview","title":"Linking the components"},{"location":"workflows/#setting-secrets","text":"If a component requires secret, it will be shown on the component box. Click on the red text to add secret from the workspace. Workspace secret has to be setup by admin.","title":"Setting Secrets"},{"location":"workflows/#volume-mount","text":"Volume mount can be added in a similar way as secret. Workspace volume has to be setup by admin.","title":"Volume mount"},{"location":"workflows/#running-a-workflow","text":"See Jobs","title":"Running a workflow"},{"location":"workspaces/","text":"Flowify utilize Role-Base Access Control (RBAC). The lowest level access control is handled by workspace. Each workspace has two roles. One for workspace admin and another for workspace user. See deployment section for adding the required roles to workspaces. All workflows in a particular workspace are executed in the same Kubernetes namespace. Access to workflows, Secrets, Jobs and Volume mounts are restricted within their own workspace. Workspace admin has permission to: Add/Modify any object inside the workspace (e.g. Secrets, Workflows, components...) Workspace user can: Run any existing workflow with new/existing parameters Create new components and workflows More details on access control for various Flowify objects are under their respective documentations.","title":"Workspaces"}]}